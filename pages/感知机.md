- ## 基本概念：
	- 感知机是**二类分类**的**线性分类**模型
	- 输入为实例的特征向量，**输出为实例的类别，取+1，-1**
	- 感知机对应于特征空间中将实例划分为正负两类的分离超平面，属于**判别模型**。
	- 基于误分类的损失函数，利用梯度下降法极小化损失函数
- 函数形式：由输入空间到输出空间：
	- f(x) = sign(w*x + b)
	- w为权值向量，b为偏置，感知机的学习就是确定w和b
	- sign为符号函数，大于等于0，取+1，小于0，取-1
- 几何解释：
	- 线性方程 w*x + b = 0对应特征空间中的一个超平面，该分离超平面能将所有实例点（特征向量）分为正负两类。
	-
- ## 感知机学习策略
- 定义数据集的线性可分性：
	- 存在一个分离超平面，能将数据集的正实例点和负实例点完全正确地划分到超平面的两侧，则称为线性可分数据集，否则称为线性不可分。
- **损失函数：所有误分类点到超平面S的总距离。**
	- 任意一个误分类实例点到平面S的距离公式（公式2.4）
		- 涉及w的L2范数
	- 对所有误分类点到S距离求和。
	- 损失函数是非负的，如果没有误分类点，损失函数为0，误分类点越少，损失函数越小，一个特定的样本点的损失函数：在误分类时是参数w，b的线性函数，在正确分类时是0
- 算法学习过程：
	- 误分类驱动的
	- 采用随机梯度下降法
	- 首先，任意选取一个超平面w0, b0，然后用梯度下降法不断极小化目标函数
	- 极小化过程不是一次使得M中所有误分类点梯度下降，**而是一次随机选取一个误分类点**使梯度下降。
	- 梯度计算公式（公式2.6， 2.7）
		- **虽然梯度公式涉及所有误分类点，但是在梯度更新的时候，是随机取一个误分类点进行参数更新**
- **注意点**
	- 感知机学习算法由于采用不同的初值或选取不同的误分类点，解可以是不同的
- 学习的对偶形式：
	- 基本思想：将w和b表示为实例x_i和y_i的线性组合的形式，通过求解其系数而求得w和b